{"name":"Funfetti-chicken","tagline":"Music analysis software that uses sentiment analysis to decide what foods go with what music","body":"### Welcome to Funfetti Chicken\r\nFunfetti Chicken Project Proposal\r\n\r\n###The Big Idea\r\n\r\nThe main idea of the project is to take the tone, lyrics, tempo, and rating of music to determine the emotion expressed by the music and then generate a food list that perfectly matches the song. We will be exploring the concept of audio sentiment analysis that goes beyond positive or negative and extends to anger, sadness, happiness, lethargy, and whatever else we can pull out of music. The minimum viable product will be an algorithm that judges a song’s emotion based on one of the four song aspects described above (e.g., takes in song lyrics and outputs an emotional evaluation). The stretch goal is to have algorithms looking at those four aspects, paying special attention to those we deem most capable of determining the emotion of songs, and returning a perfect accompanying food.\r\n\r\n###Learning Goals\r\n\r\nWe want to learn to analyze data more specifically and more in depth than we had in previous projects. We hope to learn to effectively interpret multiple different types of data at a time, and figure out how to prioritize each type or combine multiple types.\r\n\r\n###Implementation Plan\r\n\r\nOur implementation would divide the overarching goal into multiple sub-functions or modules, which would converge to produce the output. \r\n\r\n\r\nLibraries which might prove useful: Pattern (for lyric analysis), Librosa (for tempo/key analysis), Echo Nest (for key/instrument analysis), \r\n\r\n###Project schedule\r\n\r\nweeks 1-2: complete MVP\r\nweeks 3-4: finish algorithms for at least ¾ major song aspects\r\nweeks 5-6: finish algorithms, add the food side, combine the algorithms into one program that work together\r\n\r\n###Collaboration plan\r\n\r\nWe’re used to working on a coding problem individually for a long period of time until eventually we figure it out, but we decided that it may be beneficial to try a different approach for this project. We’re going to try pair programming to see if that method works better for us, and if it doesn’t work very well we may switch to individually working on modules of the program and then combining them. We have four elements of music that we plan to analyze, so that will divide nicely among four people whether we’re pair programming or not. Once we’ve finished the algorithms for these elements, we’ll put our combined code on github and work on it as a whole. \r\n\r\n###Risks\r\n\r\n     Integrating the algorithms to analyze the music and translate them to food. In order to get an accurate translation we have to analyze many variables for each song and match them with correlated food. Getting the algorithms to effectively evaluate the music for sentiment as complicated as what we want could prove very tricky.\r\n\r\n\r\n###Additional Course Content\r\n\r\nIf we were to cover ways in which text analysis determines sentiment, that would be helpful for us in branching our sentiment analysis beyond just positive or negative. Otherwise we would have to rely mostly on libraries already available instead of building our own tools.\r\n\r\n________________________________________________________________________________________________________________________\r\n###Technical Review\r\n\r\n###Background and Context:\r\nOur project is an investigation of song sentiment and the ways we can use programming to analyze it. The end goal is to use machine learning to give our program the ability to categorize new songs based on a training set. We are using a variety of APIs to gather essential data on songs in order to create the training set and give the program the information it needs to analyze new songs. Once the sentiment of the song has been realized, the program will offer choice foods to go with the song.\r\n###Key Questions:\r\nWhat we most want to learn from the review is what machine learning technique will be best for the information we are trying to gather. Also, we need to find an efficient way of generating a training data set, so any opinions on other APIs that would help our project would be greatly appreciated.\r\n###Agenda:\r\nWe plan to give a brief summary of what our project is, what the finished product will look like, and what we have so far. The rest of the time will be allotted to surveying the group about the key questions we have listed above and facilitating general discussion of our ideas and chosen methods.\r\n___________________________________________________________________________________________________________________________\r\n###                                                   After the Review:\r\n###Feedback and Decisions:\r\nThe advice we received on machine learning was that we should try to look for trends in the data, and that thought pushed us towards Association rule learning because it is effective at finding correlations between variables, which is exactly what we are looking for. For generating the training data, we were told that the Rovi API was a good option for getting the moods of songs, saving us the trouble of having to manually listen to songs and enter in how we thought they felt. This API allows us to get an unbiased opinion on the mood of the songs. \r\n\r\n###Review process reflection:\r\nThe review was an overall success. We got the questions we needed answered answered and we got interesting new leads regarding everything we were concerned about. We may have provided too little context for the groups to be of a large help in regard to the machine learning, but we had decided it was too hard to get a good enough understanding of machine learning to really help our team in a short period of time. In regard to the agenda, we stuck to it fairly well, only needing to backtrack and re-explain things once or twice. The time we allotted for general discussion was very rewarding and worth the effort. We are going to plan our discussion of machine learning a little better and try to present people with the opportunity to go beyond what we even considered. \r\n___________________________________________________________________________________________________________________________\r\n###                              Preparation & Framing Document for team Funfetti Chicken:\r\n\r\n###Background and Context:\r\n    Our project is based on taking a song, finding relevant information (e.g., lyrics, tempo, key) about it, and translating that to a sentiment. As a bit of a \"flourish,\" the sentiments will then be mapped to an appropriate food with a (very subjective) pseudo-dictionary of our own devising.\r\n    Currently, we've written and assembled the bulk of the \"infrastructure\" needed to get song information in the first place, and have built a small database of songs & song data for us to access online. The \"moving parts\" which we currently have are:\r\n        - Song data harvesting--using Echo Nest API to search for, and retrieve, information about a song.\r\n        - Database construction/storage - automating Echo Nest searches, and storing information (like tempo, name, artist) in a song_data object which is then preserved (with the Pickle module) for future reference.\r\n        - Lyrics harvesting - getting lyrics from the web for a song using requests (a web accessing package) and string parsing (to turn the web output into something which python can \"eval\").\r\n        - Lyrics sentiment analysis - using Pattern to get the overall \"mood\" of a song's lyrics. The lyrics themselves come from the aforementioned lyrics harvesting.\r\n        - Song gathering - getting songs from the \"Billboard\" top 100 weekly songs. Uses HTML to gather songs from several years of Billboard data, and then collate this information into a list of (\"artist\",\"song\") tuples which can then be passed on to the database construction.\r\n\r\n###Key Questions:\r\n    We've created something to get, and store, nearly every bit of information we could want about a song. However, we're somewhat at a loss for what to do next.\r\n    In particular: we want to use a machine learning approach to prepare our sentiment-classifying algorithm. We've got a couple of major questions as to how this can be addressed:\r\n        - What sort of machine learning algorithms and/or packages would be best to use?\r\n            - Relatedly, what approach should we take?\r\n                - Should we, say, have an input of (tempo, key, lyric_sentiment, etc) and an output of (happiness, anger, etc)?            \r\n                - Or is it better to just train for a single output: say, 3-4 variables in and 1 out?\r\n            -Relevant info: None of us know anything about writing an algorithm for ML. We could try to as a stretch goal, but it would be handy to adapt existing libraries/tools.\r\n\r\n        - How should we acquire training data?\r\n            - We can get very general/vague information from the \"Rovi\" API - should we just get the moods for a lot of songs, and use some to train and some to test?\r\n            - Alternatively, should we try to use human classification to get initial training data?\r\n            - (Or, something else?)\r\n\r\n###Agenda:\r\n    1. Begin with a brief overview of our project, and the state we're at right now.\r\n    2. Move on to ideating on the ML front. We've addressed most of our pressing concerns vis-a-vis gathering information, songs, etc. in the first place - but, now we're uncertain what to *do* with this data; as such, this seems like a good focus.\r\n    3. Depending on which ideas seem promising (and, using a few of our current ideas/possibilities), some \"Technical discussion\" as to what sorts of structures, algorithms, packages, etc. could be used to make ML ideas work.\r\n\r\n\r\n\r\n___________________________________________________________________________________________________________________________\r\n###                                                      After the Code Review\r\n###Feedback and Decisions:\r\nWe did not get a large amount of feedback on what path we should take in terms of our machine learning choices, leaving us to decide on the path ourselves through independent research. It was agreed upon that having multiple outputs from the ML was superior to having just one, and after careful consideration we have decided to push off making multiple outputs our goal until our base model works. \r\n###Reflection\r\nOverall our key questions went unanswered, most likely because we failed to communicate our needs correctly to those that knew enough to answer. Alternatively, there was no one in the group with the in depth knowledge of machine learning required to guide us in our quest. We do not believe this could have been solved with pre-class reading simply because the documentation for machine learning in general is dense and borderline impossible to summarize into a small reading source. Unfortunately, aside from attempting to better communicate our needs in terms of the machine learning guidance, there isn't much we could have done to get more from the review. \r\n\r\n### Authors and Contributors\r\n@buttegab, @jgraupirozzi, @matthewruehle, and @adority\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}